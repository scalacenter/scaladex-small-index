{
  "organization" : "projectglow",
  "repository" : "glow",
  "creationDate" : 1619563758000,
  "githubStatus" : {
    "Ok" : {
      "updateDate" : 1644285925081
    }
  },
  "githubInfo" : {
    "homepage" : "https://projectglow.io",
    "description" : "An open-source toolkit for large-scale genomic analysis",
    "logo" : "https://avatars.githubusercontent.com/u/56176481?v=4",
    "stars" : 189,
    "forks" : 61,
    "watchers" : 18,
    "issues" : 58,
    "creationDate" : 1570224407000,
    "readme" : "<div id=\"readme\" class=\"md\" data-path=\"README.md\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><p align=\"center\" dir=\"auto\">\n  <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"static/glow_logo_horiz_color.png\"><img src=\"static/glow_logo_horiz_color.png\" width=\"300px\" style=\"max-width: 100%;\"></a>\n</p>\n<p align=\"center\" dir=\"auto\">\n\tAn open-source toolkit for large-scale genomic analyes\n  <br>\n  <a href=\"https://glow.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><strong>Explore the docs »</strong></a>\n  <br>\n  <br>\n  <a href=\"https://github.com/projectglow/glow/issues\">Issues</a>\n  ·\n  <a href=\"https://groups.google.com/forum/#!forum/proj-glow\" rel=\"nofollow\">Mailing list</a>\n  ·\n\t<a href=\"https://join.slack.com/t/proj-glow/shared_invite/enQtNzkwNDE4MzMwMTk5LTE2M2JiMjQ1ZDgyYWNkZTFiY2QyYWE0NGI2YWY3ODY3NmEwNmU5OGQzODcxMDBlYzY2YmYzOGM1YTcyYTRhYjA\" rel=\"nofollow\">Slack</a>\n</p>\n<p dir=\"auto\">Glow is an open-source toolkit to enable bioinformatics at biobank-scale and beyond.</p>\n<p dir=\"auto\"><a href=\"https://circleci.com/gh/projectglow/glow\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/192b22a31dec6e47ed7d80011edecb6fb478aa2b727c509b10fa4f0550ed6ae8/68747470733a2f2f636972636c6563692e636f6d2f67682f70726f6a656374676c6f772f676c6f772e7376673f7374796c653d73766726636972636c652d746f6b656e3d37353131663730623263383130613138653838623563353337623034313065383264623836313764\" alt=\"CircleCI\" data-canonical-src=\"https://circleci.com/gh/projectglow/glow.svg?style=svg&amp;circle-token=7511f70b2c810a18e88b5c537b0410e82db8617d\" style=\"max-width: 100%;\"></a>\n<a href=\"https://glow.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/44caf13a3e3f7de5ebe00420af08972d3ab8a6b86f82d142c91b2bdd30bcb859/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f676c6f772f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/glow/badge/?version=latest\" style=\"max-width: 100%;\"></a>\n<a href=\"https://pypi.org/project/glow.py/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/21ad159176af61e1216bdbf38d0cf49e7de5b23b0efa09b05e85efc88ff271a8/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f676c6f772e70792e737667\" alt=\"PyPi\" data-canonical-src=\"https://img.shields.io/pypi/v/glow.py.svg\" style=\"max-width: 100%;\"></a>\n<a href=\"https://anaconda.org/conda-forge/glow\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/f45796623b25147c8d12dddaef61c87e87b3d9e28585fe46d5dabe70703b4b63/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f676c6f772e737667\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/glow.svg\" style=\"max-width: 100%;\"></a>\n<a href=\"https://mvnrepository.com/artifact/io.projectglow\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/afe741d25d39c243dd043829018acbe6092a5b17c357833b043a33f521fea544/68747470733a2f2f696d672e736869656c64732e696f2f6d6176656e2d63656e7472616c2f762f696f2e70726f6a656374676c6f772f676c6f772d737061726b335f322e31322e737667\" alt=\"Maven Central\" data-canonical-src=\"https://img.shields.io/maven-central/v/io.projectglow/glow-spark3_2.12.svg\" style=\"max-width: 100%;\"></a>\n<a href=\"https://codecov.io/gh/projectglow/glow\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/664bda5a364d1c7d0839528dedb263d2532b45f7163fd868097991fddba5f842/68747470733a2f2f636f6465636f762e696f2f67682f70726f6a656374676c6f772f676c6f772f6272616e63682f6d61737465722f67726170682f62616467652e737667\" alt=\"Coverage Status\" data-canonical-src=\"https://codecov.io/gh/projectglow/glow/branch/master/graph/badge.svg\" style=\"max-width: 100%;\"></a>\n<a href=\"https://zenodo.org/badge/latestdoi/212904926\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4923a6bfeaa1976884456f405c3334394a716939e5be22cbc449e9c2ecb588bf/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3231323930343932362e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/212904926.svg\" style=\"max-width: 100%;\"></a></p>\n<h1 dir=\"auto\"><a id=\"user-content-easy-to-get-started\" class=\"anchor\" aria-hidden=\"true\" href=\"#easy-to-get-started\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Easy to get started</h1>\n<p dir=\"auto\">The toolkit includes the building blocks that you need to perform the most common analyses right away:</p>\n<ul dir=\"auto\">\n<li>Load VCF, BGEN, and Plink files into distributed DataFrames</li>\n<li>Perform quality control and data manipulation with built-in functions</li>\n<li>Variant normalization and liftOver</li>\n<li>Perform genome-wide association studies</li>\n<li>Integrate with Spark ML libraries for population stratification</li>\n<li>Parallelize command line tools to scale existing workflows</li>\n</ul>\n<h1 dir=\"auto\"><a id=\"user-content-built-to-scale\" class=\"anchor\" aria-hidden=\"true\" href=\"#built-to-scale\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Built to scale</h1>\n<p dir=\"auto\">Glow makes genomic data work with Spark, the leading engine for working with large structured\ndatasets. It fits natively into the ecosystem of tools that have enabled thousands of organizations\nto scale their workflows to petabytes of data. Glow bridges the gap between bioinformatics and the\nSpark ecosystem.</p>\n<h1 dir=\"auto\"><a id=\"user-content-flexible\" class=\"anchor\" aria-hidden=\"true\" href=\"#flexible\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Flexible</h1>\n<p dir=\"auto\">Glow works with datasets in common file formats like VCF, BGEN, and Plink as well as\nhigh-performance big data\nstandards. You can write queries using the native Spark SQL APIs in Python, SQL, R, Java, and Scala.\nThe same APIs allow you to bring your genomic data together with other datasets such as electronic\nhealth records, real world evidence, and medical images. Glow makes it easy to parallelize existing\ntools and libraries implemented as command line tools or Pandas functions.</p>\n<h1 dir=\"auto\"><a id=\"user-content-building-and-testing\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-and-testing\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Building and Testing</h1>\n<p dir=\"auto\">This project is built using <a href=\"https://www.scala-sbt.org/1.0/docs/Setup.html\" rel=\"nofollow\">sbt</a> and Java 8.</p>\n<p dir=\"auto\">To build and run Glow, you must <a href=\"https://docs.conda.io/en/latest/miniconda.html\" rel=\"nofollow\">install conda</a> and\nactivate the environment in <code>python/environment.yml</code>.</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"conda env create -f python/environment.yml\nconda activate glow\"><pre><code>conda env create -f python/environment.yml\nconda activate glow\n</code></pre></div>\n<p dir=\"auto\">When the environment file changes, you must update the environment:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"conda env update -f python/environment.yml\"><pre><code>conda env update -f python/environment.yml\n</code></pre></div>\n<p dir=\"auto\">Start an sbt shell using the <code>sbt</code> command.</p>\n<blockquote>\n<p dir=\"auto\"><strong>FYI</strong>: The following SBT projects are built on Spark 3.1.2/Scala 2.12.8 by default. To change the Spark version and\nScala version, set the environment variables <code>SPARK_VERSION</code> and <code>SCALA_VERSION</code>.</p>\n</blockquote>\n<p dir=\"auto\">To compile the main code:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"compile\"><pre><code>compile\n</code></pre></div>\n<p dir=\"auto\">To run all Scala tests:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"core/test\"><pre><code>core/test\n</code></pre></div>\n<p dir=\"auto\">To test a specific suite:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"core/testOnly *VCFDataSourceSuite\"><pre><code>core/testOnly *VCFDataSourceSuite\n</code></pre></div>\n<p dir=\"auto\">To run all Python tests:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python/test\"><pre><code>python/test\n</code></pre></div>\n<p dir=\"auto\">These tests will run with the same Spark classpath as the Scala tests.</p>\n<p dir=\"auto\">To test a specific Python test file:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"python/pytest python/test_render_template.py\"><pre><code>python/pytest python/test_render_template.py\n</code></pre></div>\n<p dir=\"auto\">When using the <code>pytest</code> key, all arguments are passed directly to the\n<a href=\"https://docs.pytest.org/en/latest/usage.html\" rel=\"nofollow\">pytest runner</a>.</p>\n<p dir=\"auto\">To run documentation tests:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"docs/test\"><pre><code>docs/test\n</code></pre></div>\n<p dir=\"auto\">To run the Scala, Python and documentation tests:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"test\"><pre><code>test\n</code></pre></div>\n<p dir=\"auto\">To run Scala tests against the staged Maven artifact with the current stable version:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"stagedRelease/test\"><pre><code>stagedRelease/test\n</code></pre></div>\n<h2 dir=\"auto\"><a id=\"user-content-testing-code-on-a-databricks-cluster\" class=\"anchor\" aria-hidden=\"true\" href=\"#testing-code-on-a-databricks-cluster\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>Testing code on a Databricks cluster</h2>\n<p dir=\"auto\">To test your changes on a Databricks cluster, you'll need to build and install the Python and Scala artifacts.</p>\n<p dir=\"auto\">To build an uber jar (Glow + dependencies) with your changes:</p>\n<p dir=\"auto\"><code>sbt core/assembly</code></p>\n<p dir=\"auto\">The uber jar will be at a path like <code>glow/core/target/${scala_version}/${artifact-name}-assembly-${version}-SNAPSHOT.jar</code>.</p>\n<p dir=\"auto\">To build a wheel with the Python code:</p>\n<ol dir=\"auto\">\n<li>Activate the Glow dev conda environment (<code>conda activate glow</code>)</li>\n<li><code>cd</code> into the <code>python</code> directory</li>\n<li>Run <code>python setup.py bdist_wheel</code></li>\n</ol>\n<p dir=\"auto\">The wheel file will be at a path like <code>python/dist/glow.py-${version}-py3-none-any.whl</code>.</p>\n<p dir=\"auto\">You can then <a href=\"https://docs.databricks.com/libraries/index.html\" rel=\"nofollow\">install these libraries on a Databricks cluster</a>.</p>\n<h2 dir=\"auto\"><a id=\"user-content-intellij-tips\" class=\"anchor\" aria-hidden=\"true\" href=\"#intellij-tips\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg></a>IntelliJ Tips</h2>\n<p dir=\"auto\">If you use IntelliJ, you'll want to:</p>\n<ul dir=\"auto\">\n<li>Download library and SBT sources; use SBT shell for imports and build from <a href=\"https://www.jetbrains.com/help/idea/sbt.html\" rel=\"nofollow\">IntelliJ</a></li>\n<li>Set up <a href=\"https://scalameta.org/scalafmt/docs/installation.html\" rel=\"nofollow\">scalafmt on save</a></li>\n</ul>\n<p dir=\"auto\">To run Python unit tests from inside IntelliJ, you must:</p>\n<ul dir=\"auto\">\n<li>Open the \"Terminal\" tab in IntelliJ</li>\n<li>Activate the glow conda environment (<code>conda activate glow</code>)</li>\n<li>Start an sbt shell from inside the terminal (<code>sbt</code>)</li>\n</ul>\n<p dir=\"auto\">The \"sbt shell\" tab in IntelliJ will NOT work since it does not use the glow conda environment.</p>\n<p dir=\"auto\">To test or testOnly in remote debug mode with IntelliJ IDEA set the remote debug configuration in IntelliJ to 'Attach to remote JVM' mode and a specific port number (here the default port number 5005 is used) and then modify the definition of options in groupByHash function in build.sbt to</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"val options = ForkOptions().withRunJVMOptions(Vector(&quot;-Xmx1024m&quot;)).withRunJVMOptions(Vector(&quot;-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005&quot;))\"><pre><code>val options = ForkOptions().withRunJVMOptions(Vector(\"-Xmx1024m\")).withRunJVMOptions(Vector(\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005\"))\n</code></pre></div>\n</article></div>",
    "contributors" : [
      {
        "login" : "karenfeng",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/4754931?v=4",
        "url" : "https://api.github.com/users/karenfeng",
        "contributions" : 149
      },
      {
        "login" : "henrydavidge",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1473365?v=4",
        "url" : "https://api.github.com/users/henrydavidge",
        "contributions" : 116
      },
      {
        "login" : "kianfar77",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/25619085?v=4",
        "url" : "https://api.github.com/users/kianfar77",
        "contributions" : 45
      },
      {
        "login" : "williambrandler",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/51180067?v=4",
        "url" : "https://api.github.com/users/williambrandler",
        "contributions" : 43
      },
      {
        "login" : "mah-databricks",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/90000715?v=4",
        "url" : "https://api.github.com/users/mah-databricks",
        "contributions" : 2
      },
      {
        "login" : "bboutkov",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/5230985?v=4",
        "url" : "https://api.github.com/users/bboutkov",
        "contributions" : 2
      },
      {
        "login" : "bcajes",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/498608?v=4",
        "url" : "https://api.github.com/users/bcajes",
        "contributions" : 2
      },
      {
        "login" : "ahirreddy",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/153361?v=4",
        "url" : "https://api.github.com/users/ahirreddy",
        "contributions" : 1
      },
      {
        "login" : "a0x8o",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/22206500?v=4",
        "url" : "https://api.github.com/users/a0x8o",
        "contributions" : 1
      },
      {
        "login" : "kermany",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/6556219?v=4",
        "url" : "https://api.github.com/users/kermany",
        "contributions" : 1
      },
      {
        "login" : "dmoore247",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1122251?v=4",
        "url" : "https://api.github.com/users/dmoore247",
        "contributions" : 1
      },
      {
        "login" : "fnothaft",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/3752466?v=4",
        "url" : "https://api.github.com/users/fnothaft",
        "contributions" : 1
      },
      {
        "login" : "hvanhovell",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/9616802?v=4",
        "url" : "https://api.github.com/users/hvanhovell",
        "contributions" : 1
      },
      {
        "login" : "LelandBarnard",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/24434775?v=4",
        "url" : "https://api.github.com/users/LelandBarnard",
        "contributions" : 1
      },
      {
        "login" : "heuermh",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/35293?v=4",
        "url" : "https://api.github.com/users/heuermh",
        "contributions" : 1
      },
      {
        "login" : "dna0ff",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/20377386?v=4",
        "url" : "https://api.github.com/users/dna0ff",
        "contributions" : 1
      }
    ],
    "commits" : 368,
    "topics" : [
      "genomics",
      "gwas",
      "spark",
      "delta",
      "regression",
      "machine-learning",
      "population-genetics"
    ],
    "contributingGuide" : null,
    "codeOfConduct" : null,
    "chatroom" : null,
    "openIssues" : [
      {
        "number" : 480,
        "title" : "Improve handling of environment variables in the pipe transformer",
        "url" : "https://github.com/projectglow/glow/issues/480"
      },
      {
        "number" : 474,
        "title" : "VCF files with spaces in the file name cannot be read",
        "url" : "https://github.com/projectglow/glow/issues/474"
      },
      {
        "number" : 473,
        "title" : "Improve docs: Document usage of schema when reading/writing VCF",
        "url" : "https://github.com/projectglow/glow/issues/473"
      },
      {
        "number" : 472,
        "title" : "Simplify writing of sharded VCFs",
        "url" : "https://github.com/projectglow/glow/issues/472"
      },
      {
        "number" : 471,
        "title" : "Minor inconsistencies in score-logistic p-values",
        "url" : "https://github.com/projectglow/glow/issues/471"
      },
      {
        "number" : 465,
        "title" : "Hadoop 3 compatibility",
        "url" : "https://github.com/projectglow/glow/issues/465"
      },
      {
        "number" : 463,
        "title" : "quarantine functionality in pipe transformer writes out full dataset",
        "url" : "https://github.com/projectglow/glow/issues/463"
      },
      {
        "number" : 459,
        "title" : "Set explicit guidelines when running large jobs",
        "url" : "https://github.com/projectglow/glow/issues/459"
      },
      {
        "number" : 458,
        "title" : "Plink demo",
        "url" : "https://github.com/projectglow/glow/issues/458"
      },
      {
        "number" : 456,
        "title" : "Databricks TypeError: 'JavaPackage' object is not callable",
        "url" : "https://github.com/projectglow/glow/issues/456"
      },
      {
        "number" : 453,
        "title" : "Performance of split and normalize transformers",
        "url" : "https://github.com/projectglow/glow/issues/453"
      },
      {
        "number" : 451,
        "title" : "Glow implementation using Scala",
        "url" : "https://github.com/projectglow/glow/issues/451"
      },
      {
        "number" : 447,
        "title" : "ValueError: Some of types cannot be determined after inferring",
        "url" : "https://github.com/projectglow/glow/issues/447"
      },
      {
        "number" : 439,
        "title" : "AnalysisException: Undefined function: 'nullif' when exporting from Hail to Glow",
        "url" : "https://github.com/projectglow/glow/issues/439"
      },
      {
        "number" : 423,
        "title" : "PySpark 3.2.0 support",
        "url" : "https://github.com/projectglow/glow/issues/423"
      },
      {
        "number" : 421,
        "title" : "java.lang.ArrayIndexOutOfBoundsException when writing to vcf",
        "url" : "https://github.com/projectglow/glow/issues/421"
      },
      {
        "number" : 405,
        "title" : "Regression on large datasets using spot instances/preemptible VMs",
        "url" : "https://github.com/projectglow/glow/issues/405"
      },
      {
        "number" : 404,
        "title" : "Writing VCF with FloatType in INFO field fails",
        "url" : "https://github.com/projectglow/glow/issues/404"
      },
      {
        "number" : 403,
        "title" : "add automated release pipeline",
        "url" : "https://github.com/projectglow/glow/issues/403"
      },
      {
        "number" : 401,
        "title" : "Phenotypes and Covariates not automatically filtered to match genotype table",
        "url" : "https://github.com/projectglow/glow/issues/401"
      },
      {
        "number" : 399,
        "title" : "GLOW vs REGENIE",
        "url" : "https://github.com/projectglow/glow/issues/399"
      },
      {
        "number" : 395,
        "title" : "Approx firth does not handle failed fit gracefully",
        "url" : "https://github.com/projectglow/glow/issues/395"
      },
      {
        "number" : 394,
        "title" : "Integrating glow into pipeline",
        "url" : "https://github.com/projectglow/glow/issues/394"
      },
      {
        "number" : 393,
        "title" : "Better handling of missing phenotypes in step 1 and step 2 of GloWGR",
        "url" : "https://github.com/projectglow/glow/issues/393"
      },
      {
        "number" : 392,
        "title" : "Add top about yapfAll to building and testing notes for developers",
        "url" : "https://github.com/projectglow/glow/issues/392"
      },
      {
        "number" : 378,
        "title" : "Better handling of spark configs",
        "url" : "https://github.com/projectglow/glow/issues/378"
      },
      {
        "number" : 375,
        "title" : "Improve pipe transformer observability",
        "url" : "https://github.com/projectglow/glow/issues/375"
      },
      {
        "number" : 371,
        "title" : "Cannot flatten info field names containing points",
        "url" : "https://github.com/projectglow/glow/issues/371"
      },
      {
        "number" : 369,
        "title" : "mean_substitute minimal example in API fails with Invalid call to dataType on unresolved object, tree: lambda '3[sum]",
        "url" : "https://github.com/projectglow/glow/issues/369"
      },
      {
        "number" : 368,
        "title" : "How to read tsv?",
        "url" : "https://github.com/projectglow/glow/issues/368"
      },
      {
        "number" : 361,
        "title" : "reading VCF as a streaming datasource in python",
        "url" : "https://github.com/projectglow/glow/issues/361"
      },
      {
        "number" : 360,
        "title" : "PySpark and ndarray",
        "url" : "https://github.com/projectglow/glow/issues/360"
      },
      {
        "number" : 356,
        "title" : "Add tips to troubleshooting page",
        "url" : "https://github.com/projectglow/glow/issues/356"
      },
      {
        "number" : 355,
        "title" : "Is GQ re-computed after splitting multi-allelic?",
        "url" : "https://github.com/projectglow/glow/issues/355"
      },
      {
        "number" : 351,
        "title" : "Memory errors writing regression results",
        "url" : "https://github.com/projectglow/glow/issues/351"
      },
      {
        "number" : 350,
        "title" : "Saddle point approximation method produces low P values when minor allele count is low",
        "url" : "https://github.com/projectglow/glow/issues/350"
      },
      {
        "number" : 349,
        "title" : "Recommend virtual machine types when reading in large datasets",
        "url" : "https://github.com/projectglow/glow/issues/349"
      },
      {
        "number" : 348,
        "title" : "Python type casting for sample_id in pandas dataframe",
        "url" : "https://github.com/projectglow/glow/issues/348"
      },
      {
        "number" : 332,
        "title" : "Unexpected behavior when reading multiple gVCFs with tabix indices and same base name",
        "url" : "https://github.com/projectglow/glow/issues/332"
      },
      {
        "number" : 331,
        "title" : "Add parameters to control max iterations and tolerance in logistic regression fit",
        "url" : "https://github.com/projectglow/glow/issues/331"
      },
      {
        "number" : 330,
        "title" : "Option to consider last allele as reference in BGEN reader",
        "url" : "https://github.com/projectglow/glow/issues/330"
      },
      {
        "number" : 321,
        "title" : "Slow Databricks GLOW implementation",
        "url" : "https://github.com/projectglow/glow/issues/321"
      },
      {
        "number" : 315,
        "title" : "split_multiallelics replaces some genotypes fields by null and drops filters column",
        "url" : "https://github.com/projectglow/glow/issues/315"
      },
      {
        "number" : 304,
        "title" : "Running the demo notebook locally",
        "url" : "https://github.com/projectglow/glow/issues/304"
      },
      {
        "number" : 295,
        "title" : "Support outputting .sample file with BGEN writer",
        "url" : "https://github.com/projectglow/glow/issues/295"
      },
      {
        "number" : 289,
        "title" : "Move alpha into grouping expression for ridge regression fit",
        "url" : "https://github.com/projectglow/glow/issues/289"
      },
      {
        "number" : 246,
        "title" : "split_multiallelic should convert arrays to scalars",
        "url" : "https://github.com/projectglow/glow/issues/246"
      },
      {
        "number" : 199,
        "title" : "[Feature request] Make pipe transformer lazy",
        "url" : "https://github.com/projectglow/glow/issues/199"
      },
      {
        "number" : 120,
        "title" : "Support exploded genotype structs in utility functions",
        "url" : "https://github.com/projectglow/glow/issues/120"
      },
      {
        "number" : 107,
        "title" : "Generalizing variant normalization beyond VCF/BGEN representations",
        "url" : "https://github.com/projectglow/glow/issues/107"
      },
      {
        "number" : 41,
        "title" : "Support BGEN formatters for pipe",
        "url" : "https://github.com/projectglow/glow/issues/41"
      }
    ]
  },
  "settings" : {
    "defaultStableVersion" : true,
    "defaultArtifact" : null,
    "strictVersions" : false,
    "customScalaDoc" : null,
    "documentationLinks" : [
    ],
    "deprecated" : false,
    "contributorsWanted" : false,
    "artifactDeprecations" : [
    ],
    "cliArtifacts" : [
    ],
    "category" : "bioinformatics",
    "beginnerIssuesLabel" : null
  }
}