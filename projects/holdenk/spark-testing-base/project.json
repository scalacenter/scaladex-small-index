{
  "organization" : "holdenk",
  "repository" : "spark-testing-base",
  "creationDate" : 1424054310967,
  "githubStatus" : {
    "Ok" : {
      "updateDate" : 1723554995062
    }
  },
  "githubInfo" : {
    "homepage" : null,
    "description" : "Base classes to use when writing tests with Spark",
    "logo" : "https://avatars.githubusercontent.com/u/59893?v=4",
    "stars" : 1506,
    "forks" : 359,
    "watchers" : 77,
    "issues" : 105,
    "creationDate" : 1422656639000,
    "readme" : "<div id=\"readme\" class=\"md\" data-path=\"README.md\"><article class=\"markdown-body entry-content container-lg\" itemprop=\"text\"><p dir=\"auto\"><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/holdenk/spark-testing-base/actions/workflows/github-actions-basic.yml/badge.svg?branch=main\"><img src=\"https://github.com/holdenk/spark-testing-base/actions/workflows/github-actions-basic.yml/badge.svg?branch=main\" alt=\"build status\" style=\"max-width: 100%;\"></a></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h1 class=\"heading-element\" dir=\"auto\">spark-testing-base</h1><a id=\"user-content-spark-testing-base\" class=\"anchor\" aria-label=\"Permalink: spark-testing-base\" href=\"#spark-testing-base\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Base classes to use when writing tests with Spark.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Why?</h2><a id=\"user-content-why\" class=\"anchor\" aria-label=\"Permalink: Why?\" href=\"#why\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">You've written an awesome program in Spark and now its time to write some tests. Only you find yourself writing the code to setup and tear down local mode Spark in between each suite and you say to your self:\nThis is not my beautiful code.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">How?</h2><a id=\"user-content-how\" class=\"anchor\" aria-label=\"Permalink: How?\" href=\"#how\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">So you include com.holdenkarau.spark-testing-base [spark_version]_1.4.0 and extend one of the classes and write some simple tests instead.  For example to include this in a project using Spark 3.0.0:</p>\n<div class=\"highlight highlight-source-scala notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"&quot;com.holdenkarau&quot; %% &quot;spark-testing-base&quot; % &quot;3.0.0_1.4.0&quot; % &quot;test&quot;\"><pre><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>com.holdenkarau<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%%</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>spark-testing-base<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>3.0.0_1.4.0<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>test<span class=\"pl-pds\">\"</span></span></pre></div>\n<p dir=\"auto\">or</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"&lt;dependency&gt;\n\t&lt;groupId&gt;com.holdenkarau&lt;/groupId&gt;\n\t&lt;artifactId&gt;spark-testing-base_2.12&lt;/artifactId&gt;\n\t&lt;version&gt;${spark.version}_1.4.0&lt;/version&gt;\n\t&lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\"><pre class=\"notranslate\"><code>&lt;dependency&gt;\n\t&lt;groupId&gt;com.holdenkarau&lt;/groupId&gt;\n\t&lt;artifactId&gt;spark-testing-base_2.12&lt;/artifactId&gt;\n\t&lt;version&gt;${spark.version}_1.4.0&lt;/version&gt;\n\t&lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre></div>\n<p dir=\"auto\">How to use it inside your code? have a look at the <a href=\"https://github.com/holdenk/spark-testing-base/wiki\">wiki</a> page.</p>\n<p dir=\"auto\">The <a href=\"https://mvnrepository.com/artifact/com.holdenkarau\" rel=\"nofollow\">Maven repositories page for spark-testing-base</a> lists the releases available.</p>\n<p dir=\"auto\">The Python package of spark-testing-base is available via:</p>\n<ul dir=\"auto\">\n<li>PyPI: <a href=\"https://pypi.org/project/spark-testing-base/\" rel=\"nofollow\">https://pypi.org/project/spark-testing-base/</a>, e.g. <code>pip install spark-testing-base</code></li>\n<li>Conda: <a href=\"https://anaconda.org/conda-forge/spark-testing-base\" rel=\"nofollow\">https://anaconda.org/conda-forge/spark-testing-base</a>, e.g. <code>conda install -c conda-forge spark-testing-base</code></li>\n</ul>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Minimum Memory Requirements and OOMs</h2><a id=\"user-content-minimum-memory-requirements-and-ooms\" class=\"anchor\" aria-label=\"Permalink: Minimum Memory Requirements and OOMs\" href=\"#minimum-memory-requirements-and-ooms\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">The default SBT testing java options are too small to support running many of the tests due to the need to launch Spark in local mode. To increase the amount of memory in a build.sbt file you can add:</p>\n<div class=\"highlight highlight-source-scala notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"fork in Test := true\njavaOptions ++= Seq(&quot;-Xms8G&quot;, &quot;-Xmx8G&quot;, &quot;-XX:MaxPermSize=4048M&quot;, &quot;-XX:+CMSClassUnloadingEnabled&quot;)\"><pre>fork in <span class=\"pl-en\">Test</span> <span class=\"pl-k\">:</span><span class=\"pl-k\">=</span> <span class=\"pl-c1\">true</span>\njavaOptions <span class=\"pl-k\">++</span><span class=\"pl-k\">=</span> <span class=\"pl-en\">Seq</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-Xms8G<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-Xmx8G<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-XX:MaxPermSize=4048M<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-XX:+CMSClassUnloadingEnabled<span class=\"pl-pds\">\"</span></span>)</pre></div>\n<p dir=\"auto\">Note: if your running in JDK17+ PermSize and ClassnloadingEnabled have been removed so it becomes:</p>\n<div class=\"highlight highlight-source-scala notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"fork in Test := true\njavaOptions ++= Seq(&quot;-Xms8G&quot;, &quot;-Xmx8G&quot;),\"><pre>fork in <span class=\"pl-en\">Test</span> <span class=\"pl-k\">:</span><span class=\"pl-k\">=</span> <span class=\"pl-c1\">true</span>\njavaOptions <span class=\"pl-k\">++</span><span class=\"pl-k\">=</span> <span class=\"pl-en\">Seq</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-Xms8G<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>-Xmx8G<span class=\"pl-pds\">\"</span></span>),</pre></div>\n<p dir=\"auto\">If using surefire you can add:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"&lt;argLine&gt;-Xmx2048m -XX:MaxPermSize=2048m&lt;/argLine&gt;\"><pre class=\"notranslate\"><code>&lt;argLine&gt;-Xmx2048m -XX:MaxPermSize=2048m&lt;/argLine&gt;\n</code></pre></div>\n<p dir=\"auto\">Note: the specific memory values are examples only (and the values used to run spark-testing-base's own tests).</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Special considerations</h2><a id=\"user-content-special-considerations\" class=\"anchor\" aria-label=\"Permalink: Special considerations\" href=\"#special-considerations\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Make sure to disable parallel execution.</p>\n<p dir=\"auto\">In sbt you can add:</p>\n<div class=\"highlight highlight-source-scala notranslate position-relative overflow-auto\" dir=\"auto\" data-snippet-clipboard-copy-content=\"parallelExecution in Test := false\"><pre>parallelExecution in <span class=\"pl-en\">Test</span> <span class=\"pl-k\">:</span><span class=\"pl-k\">=</span> <span class=\"pl-c1\">false</span></pre></div>\n<p dir=\"auto\">In surefire make sure that forkCount is set to 1 and reuseForks is true.</p>\n<p dir=\"auto\">If your testing Spark SQL CodeGen make sure to set SPARK_TESTING=true</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h3 class=\"heading-element\" dir=\"auto\">Codegen tests and Running Spark Testing Base's own tests</h3><a id=\"user-content-codegen-tests-and-running-spark-testing-bases-own-tests\" class=\"anchor\" aria-label=\"Permalink: Codegen tests and Running Spark Testing Base's own tests\" href=\"#codegen-tests-and-running-spark-testing-bases-own-tests\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">If you are testing codegen it's important to have SPARK_TESTING set to yes, as we do in our github actions.</p>\n<p dir=\"auto\"><code>SPARK_TESTING=yes ./build/sbt clean +compile +test -DsparkVersion=$SPARK_VERSION</code></p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Where is this from?</h2><a id=\"user-content-where-is-this-from\" class=\"anchor\" aria-label=\"Permalink: Where is this from?\" href=\"#where-is-this-from\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Some of this code is a stripped down version of the test suite bases that are in Apache Spark but are not accessible. Other parts are also inspired by sscheck (scalacheck generators for Spark).</p>\n<p dir=\"auto\">Other parts of this are implemented on top of the test suite bases to make your life even easier.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">How do I build this?</h2><a id=\"user-content-how-do-i-build-this\" class=\"anchor\" aria-label=\"Permalink: How do I build this?\" href=\"#how-do-i-build-this\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">This project is built with sbt.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">What are some other options?</h2><a id=\"user-content-what-are-some-other-options\" class=\"anchor\" aria-label=\"Permalink: What are some other options?\" href=\"#what-are-some-other-options\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">While we hope you choose our library, <a href=\"https://github.com/juanrh/sscheck\">https://github.com/juanrh/sscheck</a> , <a href=\"https://github.com/hammerlab/spark-tests\">https://github.com/hammerlab/spark-tests</a> , <a href=\"https://github.com/wdm0006/DummyRDD\">https://github.com/wdm0006/DummyRDD</a> , and more <a href=\"https://www.google.com/search?q=python+spark+testing+libraries\" rel=\"nofollow\">https://www.google.com/search?q=python+spark+testing+libraries</a> exist as options.</p>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\"><a href=\"RELEASE_NOTES.md\">Release Notes</a></h2><a id=\"user-content-release-notes\" class=\"anchor\" aria-label=\"Permalink: Release Notes\" href=\"#release-notes\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<div class=\"markdown-heading\" dir=\"auto\"><h2 class=\"heading-element\" dir=\"auto\">Security Disclosure e-mails</h2><a id=\"user-content-security-disclosure-e-mails\" class=\"anchor\" aria-label=\"Permalink: Security Disclosure e-mails\" href=\"#security-disclosure-e-mails\"><svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></div>\n<p dir=\"auto\">Have you found a security concern? Please let us know</p>\n<p dir=\"auto\">See <a href=\"https://github.com/holdenk/spark-testing-base/blob/main/SECURITY.md\">https://github.com/holdenk/spark-testing-base/blob/main/SECURITY.md</a></p>\n</article></div>",
    "contributors" : [
      {
        "login" : "holdenk",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/59893?v=4",
        "url" : "https://github.com/holdenk",
        "contributions" : 566
      },
      {
        "login" : "mahmoudhanafy",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/3827156?v=4",
        "url" : "https://github.com/mahmoudhanafy",
        "contributions" : 79
      },
      {
        "login" : "scala-steward",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/43047562?v=4",
        "url" : "https://github.com/scala-steward",
        "contributions" : 19
      },
      {
        "login" : "MrPowers",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/2722395?v=4",
        "url" : "https://github.com/MrPowers",
        "contributions" : 8
      },
      {
        "login" : "rylanhalteman",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/2278079?v=4",
        "url" : "https://github.com/rylanhalteman",
        "contributions" : 7
      },
      {
        "login" : "zouzias",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1871144?v=4",
        "url" : "https://github.com/zouzias",
        "contributions" : 6
      },
      {
        "login" : "kaatzee",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/2965012?v=4",
        "url" : "https://github.com/kaatzee",
        "contributions" : 5
      },
      {
        "login" : "limansky",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/111185?v=4",
        "url" : "https://github.com/limansky",
        "contributions" : 5
      },
      {
        "login" : "eruizalo",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/8049818?v=4",
        "url" : "https://github.com/eruizalo",
        "contributions" : 3
      },
      {
        "login" : "Wosin",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/7119802?v=4",
        "url" : "https://github.com/Wosin",
        "contributions" : 3
      },
      {
        "login" : "bryanyang0528",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/5171607?v=4",
        "url" : "https://github.com/bryanyang0528",
        "contributions" : 2
      },
      {
        "login" : "dbast",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/2790401?v=4",
        "url" : "https://github.com/dbast",
        "contributions" : 2
      },
      {
        "login" : "hgiddens",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/198783?v=4",
        "url" : "https://github.com/hgiddens",
        "contributions" : 2
      },
      {
        "login" : "nightscape",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/35170?v=4",
        "url" : "https://github.com/nightscape",
        "contributions" : 2
      },
      {
        "login" : "sathiyapk",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/5880194?v=4",
        "url" : "https://github.com/sathiyapk",
        "contributions" : 2
      },
      {
        "login" : "JoshRosen",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/50748?v=4",
        "url" : "https://github.com/JoshRosen",
        "contributions" : 1
      },
      {
        "login" : "juanrh",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/895341?v=4",
        "url" : "https://github.com/juanrh",
        "contributions" : 1
      },
      {
        "login" : "markdessain",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/230477?v=4",
        "url" : "https://github.com/markdessain",
        "contributions" : 1
      },
      {
        "login" : "morazow",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/916295?v=4",
        "url" : "https://github.com/morazow",
        "contributions" : 1
      },
      {
        "login" : "ponkin",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/323904?v=4",
        "url" : "https://github.com/ponkin",
        "contributions" : 1
      },
      {
        "login" : "sgt",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/5119?v=4",
        "url" : "https://github.com/sgt",
        "contributions" : 1
      },
      {
        "login" : "ac27182",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/42341528?v=4",
        "url" : "https://github.com/ac27182",
        "contributions" : 1
      },
      {
        "login" : "chiefmanc",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/11571352?v=4",
        "url" : "https://github.com/chiefmanc",
        "contributions" : 1
      },
      {
        "login" : "mandoz",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1105556?v=4",
        "url" : "https://github.com/mandoz",
        "contributions" : 1
      },
      {
        "login" : "pchundi",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/4728134?v=4",
        "url" : "https://github.com/pchundi",
        "contributions" : 1
      },
      {
        "login" : "rgarciate",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/18609971?v=4",
        "url" : "https://github.com/rgarciate",
        "contributions" : 1
      },
      {
        "login" : "siklosid",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/11415774?v=4",
        "url" : "https://github.com/siklosid",
        "contributions" : 1
      },
      {
        "login" : "smadarasmi",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/23423749?v=4",
        "url" : "https://github.com/smadarasmi",
        "contributions" : 1
      },
      {
        "login" : "smiklos",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/3218812?v=4",
        "url" : "https://github.com/smiklos",
        "contributions" : 1
      },
      {
        "login" : "jerrypnz",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/292028?v=4",
        "url" : "https://github.com/jerrypnz",
        "contributions" : 1
      },
      {
        "login" : "jackcviers",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/660372?v=4",
        "url" : "https://github.com/jackcviers",
        "contributions" : 1
      },
      {
        "login" : "falloutdurham",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/97861?v=4",
        "url" : "https://github.com/falloutdurham",
        "contributions" : 1
      },
      {
        "login" : "helfper",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/2981969?v=4",
        "url" : "https://github.com/helfper",
        "contributions" : 1
      },
      {
        "login" : "gneotux",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1918857?v=4",
        "url" : "https://github.com/gneotux",
        "contributions" : 1
      },
      {
        "login" : "felipehummel",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/21449?v=4",
        "url" : "https://github.com/felipehummel",
        "contributions" : 1
      },
      {
        "login" : "felipefzdz",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/369379?v=4",
        "url" : "https://github.com/felipefzdz",
        "contributions" : 1
      },
      {
        "login" : "edmondop",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/812841?v=4",
        "url" : "https://github.com/edmondop",
        "contributions" : 1
      },
      {
        "login" : "lunaticare",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/947471?v=4",
        "url" : "https://github.com/lunaticare",
        "contributions" : 1
      },
      {
        "login" : "dmvieira",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1108613?v=4",
        "url" : "https://github.com/dmvieira",
        "contributions" : 1
      },
      {
        "login" : "buildlackey",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/1577925?v=4",
        "url" : "https://github.com/buildlackey",
        "contributions" : 1
      },
      {
        "login" : "brkyvz",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/5243515?v=4",
        "url" : "https://github.com/brkyvz",
        "contributions" : 1
      },
      {
        "login" : "bryanv",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/113546?v=4",
        "url" : "https://github.com/bryanv",
        "contributions" : 1
      },
      {
        "login" : "borisclemencon",
        "avatarUrl" : "https://avatars.githubusercontent.com/u/10812246?v=4",
        "url" : "https://github.com/borisclemencon",
        "contributions" : 1
      }
    ],
    "commits" : 739,
    "topics" : [
    ],
    "contributingGuide" : "https://github.com/holdenk/spark-testing-base/blob/main/CONTRIBUTING.md",
    "codeOfConduct" : "https://github.com/holdenk/spark-testing-base/blob/main/CODE_OF_CONDUCT.md",
    "openIssues" : [
      {
        "number" : 418,
        "title" : "Replace deprecated SQLContext with SparkSession for DataFrame / DataSet / RDD generators",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/418"
      },
      {
        "number" : 413,
        "title" : "Codec [lz4] is not available. Consider setting spark.io.compression.codec=snappy ",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/413"
      },
      {
        "number" : 400,
        "title" : "What is the reason this project uses inheritance rather than implementing Junit's Rule?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/400"
      },
      {
        "number" : 354,
        "title" : "Unable to run tests with Spark v3.2.1 and scalatest v3.2.x",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/354"
      },
      {
        "number" : 350,
        "title" : "Add module supporting munit",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/350"
      },
      {
        "number" : 349,
        "title" : "saveAsTable function doesn't create a table after updating to the spark 3.1.1",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/349"
      },
      {
        "number" : 348,
        "title" : "ZIO-test support ? ",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/348"
      },
      {
        "number" : 342,
        "title" : "Expected instance not static method org.scalatest.Assertions in DataFrame and DataSet SuitBase",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/342"
      },
      {
        "number" : 341,
        "title" : "Tests always fail if I have more than one test file extends `StreamingSuiteBase`",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/341"
      },
      {
        "number" : 340,
        "title" : "Need Junit 5 Support",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/340"
      },
      {
        "number" : 339,
        "title" : "Setting dedicated warehouse and metastore temp-directory doens't work",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/339"
      },
      {
        "number" : 333,
        "title" : "Reduce log in unit test",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/333"
      },
      {
        "number" : 331,
        "title" : "Can't publish a local version",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/331"
      },
      {
        "number" : 324,
        "title" : "SparkSession with DeltaLake related settings",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/324"
      },
      {
        "number" : 321,
        "title" : "Building Spark session fails with Hadoop 3 because of Hive Shims",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/321"
      },
      {
        "number" : 317,
        "title" : "Hortonworks Hive Warehouse Connector & Hadoop 3",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/317"
      },
      {
        "number" : 315,
        "title" : "NoSuchMethodError: org.scalatest.Assertions.assertionsHelper",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/315"
      },
      {
        "number" : 314,
        "title" : "New python release",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/314"
      },
      {
        "number" : 313,
        "title" : "Add support for Spark Streaming Kafka 0.10",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/313"
      },
      {
        "number" : 309,
        "title" : "Custom ArrayType Fields",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/309"
      },
      {
        "number" : 307,
        "title" : "A lot of exceptions during cleanup",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/307"
      },
      {
        "number" : 302,
        "title" : "Returning nulls for nullable types",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/302"
      },
      {
        "number" : 297,
        "title" : "Option to turn Spark UI back on ?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/297"
      },
      {
        "number" : 292,
        "title" : "Hive support is required to CREATE Hive TABLE (AS SELECT);;",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/292"
      },
      {
        "number" : 289,
        "title" : "py SparkTestingBase: incorrect code to instantiate SparkSession",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/289"
      },
      {
        "number" : 285,
        "title" : "Rows only in test missing after switch to Kryo",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/285"
      },
      {
        "number" : 279,
        "title" : "Explore if pytest-xdist can work with spark tests",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/279"
      },
      {
        "number" : 278,
        "title" : "Use same Hadoop version as spark target?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/278"
      },
      {
        "number" : 272,
        "title" : "More info when comparing different DataFrame/DataSet",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/272"
      },
      {
        "number" : 269,
        "title" : "Misleading error when comparing resutls",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/269"
      },
      {
        "number" : 267,
        "title" : "Temporary warehouse on local is not a valid hdfs path (SharedSparkContext)",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/267"
      },
      {
        "number" : 265,
        "title" : "Dependency issues with  spark-testing-base_2.10, version 1.6.3_0.10.0",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/265"
      },
      {
        "number" : 261,
        "title" : "Global spark configuration changes are not maintained during Maven tests",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/261"
      },
      {
        "number" : 260,
        "title" : "hadoop-hdfs: NoSuchMethodError - org.apache.hadoop.tracing.SpanReceiverHost.getInstance",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/260"
      },
      {
        "number" : 259,
        "title" : "Exposing Builder object created in DataFrameSuiteBaseLike",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/259"
      },
      {
        "number" : 247,
        "title" : "Comparing RDD of org.apache.spark.sql.Row containing byte[] as values fails for the same provided RDD",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/247"
      },
      {
        "number" : 243,
        "title" : "assertDataFrameApproximateEquals failed",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/243"
      },
      {
        "number" : 242,
        "title" : "SqlContext test cases not running..",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/242"
      },
      {
        "number" : 240,
        "title" : "Parallel Execution",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/240"
      },
      {
        "number" : 239,
        "title" : "Multiple Coverage Highlighting in the build",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/239"
      },
      {
        "number" : 237,
        "title" : "RDDComparisons could use a more descriptive error",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/237"
      },
      {
        "number" : 236,
        "title" : "assertDataFrameEquals message says that 2 schemas are different after printing out the exact same schemas",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/236"
      },
      {
        "number" : 235,
        "title" : "PySpark: SparkTestingBaseTestCase.assertRDDEquals is not an assertion",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/235"
      },
      {
        "number" : 234,
        "title" : "Hive support lost when upgrading from spark-testing-base 2.2.0_0.9.0 to 2.3.0_0.9.0",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/234"
      },
      {
        "number" : 230,
        "title" : "Length & schema checks report expected as actual",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/230"
      },
      {
        "number" : 226,
        "title" : "python - unnecessary dependency on pytest in setup.py?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/226"
      },
      {
        "number" : 225,
        "title" : "release and publish 2.2.1_0.8.*",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/225"
      },
      {
        "number" : 224,
        "title" : "hive exception with Spark1.6",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/224"
      },
      {
        "number" : 221,
        "title" : "DataframeSuiteBase approxEquals(): need support with specified tolerence type",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/221"
      },
      {
        "number" : 219,
        "title" : " java.io.IOException: failure to login: No LoginModules configured for hadoop_simple",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/219"
      },
      {
        "number" : 217,
        "title" : "StructuredStreamingBase missing inside 2.2.0_0.8.0",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/217"
      },
      {
        "number" : 214,
        "title" : "approxEquals with relative tolerance",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/214"
      },
      {
        "number" : 212,
        "title" : "eclipse integration is not working as expected for spark 1.6.x",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/212"
      },
      {
        "number" : 211,
        "title" : "DataframeGenerator : Ensure minimum number of distinct values",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/211"
      },
      {
        "number" : 205,
        "title" : "Incompability with hbase-testing-util",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/205"
      },
      {
        "number" : 198,
        "title" : "Just make hive explicitly required",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/198"
      },
      {
        "number" : 191,
        "title" : "Guava Stopwatch bug",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/191"
      },
      {
        "number" : 186,
        "title" : "Remove EvilSessionTools / SparkSession from DataFrameSuiteBase",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/186"
      },
      {
        "number" : 180,
        "title" : "NPE when using SparkSession from DataFrameSuiteBase",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/180"
      },
      {
        "number" : 179,
        "title" : "DataFrame comparision with different schema metadata error message is confusing",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/179"
      },
      {
        "number" : 171,
        "title" : "Minicluster throws NPE on shutdown",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/171"
      },
      {
        "number" : 168,
        "title" : "Streaming testOperation() for more than 2 streams",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/168"
      },
      {
        "number" : 167,
        "title" : "Error while instantiating 'org.apache.spark.sql.hive.HiveSessionState'  on DataFrameSuiteBase",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/167"
      },
      {
        "number" : 164,
        "title" : "Testing Structured Streaming Use Cases",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/164"
      },
      {
        "number" : 163,
        "title" : "java.lang.IncompatibleClassChangeError",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/163"
      },
      {
        "number" : 161,
        "title" : "Plan to decouple with UnitTest?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/161"
      },
      {
        "number" : 142,
        "title" : "StreamingSuitBase test method ERROR",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/142"
      },
      {
        "number" : 136,
        "title" : "Checkpoint directory has not been set in the SparkContext",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/136"
      },
      {
        "number" : 134,
        "title" : "specs2 support ?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/134"
      },
      {
        "number" : 129,
        "title" : "Trying to use RDDComaprisons in scala 2.11 and spark 1.6",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/129"
      },
      {
        "number" : 128,
        "title" : "Support for ScalaTest maven plugin.",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/128"
      },
      {
        "number" : 124,
        "title" : "Switch hive dependency to non-test dep and add a note for people that want to exclude it.",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/124"
      },
      {
        "number" : 123,
        "title" : "Created shared version of DataFrameSuiteBase",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/123"
      },
      {
        "number" : 117,
        "title" : "JavaRDDComparisons on RDDs with Tuples with Decimals",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/117"
      },
      {
        "number" : 115,
        "title" : "Add test for TimeStamp generator",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/115"
      },
      {
        "number" : 108,
        "title" : "Is it possible to use DataFrameSuiteBase with FunSpec(scalatest)?",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/108"
      },
      {
        "number" : 101,
        "title" : "Not allowed to query with all of partition Keys(cassandra) with Equals",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/101"
      },
      {
        "number" : 93,
        "title" : "Point Out Spark 1.6's Hive Dependency",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/93"
      },
      {
        "number" : 75,
        "title" : "Run Streaming Tests Distributively ",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/75"
      },
      {
        "number" : 73,
        "title" : "Nice to have  more types in  DataFrameSuiteBaseLike.approxEquals",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/73"
      },
      {
        "number" : 63,
        "title" : "how to test foreachRDD in python",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/63"
      },
      {
        "number" : 58,
        "title" : "Create project page at github.io",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/58"
      },
      {
        "number" : 47,
        "title" : "Add a code of conduct",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/47"
      },
      {
        "number" : 37,
        "title" : "More documentation!",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/37"
      },
      {
        "number" : 33,
        "title" : "Serialization for Mockito improvement",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/33"
      },
      {
        "number" : 23,
        "title" : "Add Hypothesis for Python",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/23"
      },
      {
        "number" : 15,
        "title" : "Add support for quickcheck DStreams",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/15"
      },
      {
        "number" : 14,
        "title" : "Implement quickcheck type support for Java & Python",
        "url" : "https://github.com/holdenk/spark-testing-base/issues/14"
      }
    ],
    "scalaPercentage" : 78,
    "license" : "Apache-2.0",
    "commitActivity" : [
    ]
  },
  "settings" : {
    "preferStableVersion" : true,
    "defaultArtifact" : "spark-testing-base",
    "customScalaDoc" : null,
    "documentationLinks" : [
    ],
    "contributorsWanted" : false,
    "deprecatedArtifacts" : [
    ],
    "cliArtifacts" : [
    ],
    "category" : "testing",
    "chatroom" : null
  }
}